Scenario 1: Learning Rate = 0.1, Loss Function = MSELoss
Number of Batches: 128
Epoch	Loss	Validation loss	RMSE	Validation Accuracy
1	1.1684	1.1058	1.23	45.81
2	1.1075	1.1503	1.27	43.37
3	1.1010	1.0826	1.20	46.61
4	1.0952	1.0884	1.21	47.38
5	1.0840	1.0952	1.20	47.49
6	1.0767	1.0627	1.18	46.51
7	1.0687	1.1075	1.22	45.44
8	1.0620	1.0659	1.18	47.45
9	1.0530	1.0844	1.17	47.93
10	1.0476	1.0339	1.13	48.77

Scenario 2: Learning Rate = 0.1, Loss Function = MSELoss
Number of Batches: 64
Epoch	Loss	Validation loss	RMSE	Validation Accuracy
1	1.7309	1.9226	2.00	36.84
2	1.8075	2.3300	2.41	34.35
3	1.9010	2.2718	2.37	34.02
4	1.9100	2.3076	2.39	34.60
5	1.9373	1.8540	1.92	37.99
6	1.9938	1.5895	1.68	41.86
7	2.0261	1.9044	1.98	36.70
8	1.9519	2.0204	2.12	37.44
9	2.0325	2.4799	2.56	34.79
10	2.1324	1.9137	1.99	37.37

Scenario 3: Learning Rate = 0.1, Loss Function = MSELoss
Number of Batches: 32
Epoch	Loss	Validation loss	RMSE	Validation Accuracy
1	3.0546	2.8465	2.91	30.79
2	3.5143	2.9229	3.01	30.44
3	3.7377	3.3495	3.45	28.88
4	3.9733	3.0848	3.17	29.50
5	3.9070	6.0387	6.16	21.48
6	4.1317	4.2716	4.35	27.65
7	4.1077	2.7143	2.78	32.91
8	4.3613	4.1015	4.17	26.67
9	4.4279	5.9142	5.99	22.56
10	4.3396	3.9383	4.01	27.85
11	4.5635	2.2949	2.37	35.40
12	4.7746	7.1926	7.28	20.12
13	4.4850	4.2624	4.36	25.54
14	4.6642	5.3096	5.38	22.91
15	5.0184	3.3599	3.43	29.52
16	4.6898	8.1361	8.20	20.77
17	5.1678	5.4574	5.55	23.45
18	4.8856	5.2115	5.31	24.45
19	4.6374	5.5045	5.59	23.74
20	5.1683	5.5324	5.62	23.18

Scenario 4: Learning Rate = 0.1, Loss Function = MSELoss
Number of Batches: 64
Epoch	Loss	Validation loss	RMSE	Validation Accuracy
1	1.6994	1.8960	1.99	37.19
2	1.8204	2.3986	2.48	34.38
3	1.9188	1.8167	1.91	37.79
4	1.9081	1.4638	1.56	40.59
5	1.9408	1.6905	1.76	39.46
6	1.9034	1.9468	2.03	37.86
7	2.0851	2.0887	2.17	34.75
8	1.9954	3.4053	3.49	28.73
9	2.0065	1.4252	1.51	43.04
10	2.0744	1.8503	1.94	39.10
11	1.9975	1.8832	1.97	38.18
12	2.1371	2.4762	2.55	34.41
13	2.1264	2.6552	2.75	32.94
14	2.0475	1.7668	1.84	38.69
15	2.0928	2.3071	2.38	35.57
16	2.1723	2.4025	2.51	34.31
17	2.1133	2.6115	2.71	32.88
18	2.1221	2.0732	2.17	35.75
19	2.1963	1.8405	1.93	37.71
20	2.2829	1.7447	1.84	39.32
21	2.0429	1.5969	1.68	41.73
22	2.2240	2.0103	2.10	37.24
23	2.2254	2.6492	2.74	33.17
24	2.1223	2.0373	2.13	37.50
25	2.2146	3.2455	3.33	30.38
26	2.1310	2.0309	2.11	38.03
27	2.2844	2.0412	2.13	36.52
28	2.2923	2.2967	2.39	35.38
29	2.2210	1.8162	1.89	38.04
30	2.2812	1.6341	1.72	41.33
31	2.1351	2.3588	2.44	34.24
32	2.3506	1.9699	2.05	37.57
33	2.1824	1.7202	1.80	39.87
34	2.2531	1.9178	1.99	38.17
35	2.2411	2.5491	2.63	33.82
36	2.2825	2.3566	2.43	33.94
37	2.4088	2.4586	2.53	34.47
38	2.1050	2.2216	2.31	35.38
39	2.2643	1.9669	2.06	37.70
40	2.2903	2.6632	2.77	32.51
41	2.1591	2.0178	2.10	36.89
42	2.3279	3.5330	3.61	29.73
43	2.2720	2.3731	2.46	33.79
44	2.4381	3.8861	3.98	29.06
45	2.2348	2.5884	2.66	33.71
46	2.2176	1.9189	2.01	38.82
47	2.3571	2.2450	2.32	36.02
48	2.2905	2.2123	2.30	35.74
49	2.1940	2.2997	2.38	35.03
50	2.3617	1.9575	2.04	38.18
51	2.3110	2.7052	2.80	32.46
52	2.2852	1.9694	2.05	36.90
53	2.2974	2.2343	2.32	36.12
54	2.3069	3.3732	3.46	29.18
55	2.1808	1.9465	2.03	37.10
56	2.4370	1.7674	1.85	38.59
57	2.2909	4.0064	4.09	27.28
58	2.2761	2.3360	2.43	34.38
59	2.3322	2.5114	2.59	34.08
60	2.1954	2.4003	2.50	35.43
61	2.3713	1.5184	1.62	40.56
62	2.2985	2.4700	2.55	33.41
63	2.4098	1.6980	1.78	39.56
64	2.2472	2.4806	2.58	34.60
65	2.3497	1.7462	1.82	39.41
66	2.2871	1.8446	1.93	37.72
67	2.2701	2.3569	2.44	33.90
68	2.3416	2.2137	2.31	36.46
69	2.4058	2.2816	2.37	35.04
70	2.2186	2.0909	2.17	36.81
71	2.4527	3.1495	3.23	29.96
72	2.2183	2.2910	2.38	36.37
73	2.4746	2.8472	2.92	32.02
74	2.1230	1.8946	1.98	38.45
75	2.4742	2.0915	2.17	37.03
76	2.2503	2.5844	2.66	33.50
77	2.3648	3.0261	3.12	31.75
78	2.3760	2.3472	2.43	35.36
79	2.4254	2.6470	2.73	33.03
80	2.3085	2.7271	2.79	31.19
81	2.2501	3.5878	3.68	27.41
82	2.3643	1.5081	1.59	43.00
83	2.3573	1.6216	1.69	40.87
84	2.3359	3.7497	3.85	28.63
85	2.3037	1.7015	1.78	40.85
86	2.5180	1.9607	2.05	37.03
87	2.2245	1.9663	2.06	37.27
88	2.3215	2.0531	2.14	36.08
89	2.3862	2.2030	2.28	35.88
90	2.3468	2.0720	2.15	37.40
91	2.2746	2.6677	2.75	34.00
92	2.4682	2.2158	2.30	35.46
93	2.3035	2.6511	2.74	33.83
94	2.2911	2.5807	2.65	34.76
95	2.4942	2.0268	2.12	36.56
96	2.3158	2.0693	2.15	36.49
97	2.4079	1.9877	2.08	36.50
98	2.3238	2.3464	2.43	35.24
99	2.4943	2.0810	2.16	37.47
100	2.1254	1.6727	1.76	41.21

Scenario 5: Learning Rate = 0.01, Loss Function = SmoothL1Loss
Number of Batches: 128
Scheduler: StepLR
Epoch	Loss	Validation loss	RMSE	Validation Accuracy
1	0.5246	0.3431	0.90	54.48
2	0.3299	0.3339	0.87	55.36
3	0.3135	0.3292	0.86	55.63
4	0.3045	0.3284	0.86	56.09
5	0.2995	0.3277	0.86	56.28
6	0.2962	0.3250	0.85	56.10
7	0.2942	0.3247	0.85	55.77
8	0.2929	0.3235	0.84	56.53
9	0.2916	0.3286	0.87	55.72
10	0.2902	0.3236	0.84	56.17
11	0.2895	0.3224	0.84	56.02
12	0.2883	0.3264	0.84	55.41
13	0.2887	0.3257	0.85	56.54
14	0.2867	0.3214	0.84	56.36
15	0.2868	0.3306	0.87	56.74
16	0.2864	0.3221	0.84	56.82
17	0.2870	0.3206	0.84	56.71
18	0.2855	0.3285	0.87	56.09
19	0.2850	0.3228	0.85	56.83
20	0.2850	0.3257	0.85	56.26

Scenario 6: Learning Rate = 0.01, Loss Function = MSELoss
Number of Batches: 128
Scheduler: StepLR
Epoch	Loss	Validation loss	RMSE	Validation Accuracy
1	1.6358	0.8363	0.92	52.75
2	0.7839	0.7988	0.87	54.14
3	0.7417	0.7764	0.86	54.72
4	0.7204	0.7694	0.86	54.72
5	0.7066	0.7739	0.86	55.60
6	0.6963	0.7662	0.85	55.82
7	0.6891	0.7696	0.85	54.87
8	0.6853	0.7608	0.85	56.17
9	0.6821	0.7664	0.84	55.99
10	0.6779	0.7638	0.85	55.44
11	0.6756	0.7661	0.85	54.62
12	0.6749	0.7500	0.84	55.69
13	0.6723	0.7617	0.85	55.48
14	0.6697	0.7981	0.87	54.84
15	0.6684	0.7579	0.85	54.98
16	0.6659	0.7631	0.85	54.58
17	0.6670	0.7515	0.84	56.15
18	0.6641	0.7618	0.85	55.83
19	0.6645	0.7492	0.83	55.94
20	0.6632	0.7484	0.84	55.99
21	0.6630	0.7812	0.86	56.14
22	0.6619	0.8025	0.89	55.52
23	0.6627	0.7512	0.84	55.50
24	0.6589	0.7588	0.84	54.92
25	0.6613	0.7686	0.86	55.89
26	0.6589	0.7561	0.84	55.08
27	0.6590	0.7814	0.87	55.35
28	0.6581	0.7514	0.84	56.38
29	0.6586	0.7623	0.85	56.02
30	0.6560	0.7722	0.86	55.99
31	0.6577	0.7604	0.84	55.10
32	0.6563	0.7904	0.88	55.89
33	0.6568	0.7676	0.85	55.63
34	0.6557	0.7606	0.85	55.72
35	0.6555	0.7570	0.85	55.09
36	0.6543	0.7801	0.86	55.63
37	0.6542	0.7540	0.84	56.22
38	0.6543	0.7531	0.84	55.35
39	0.6560	0.7822	0.88	55.66
40	0.6527	0.7587	0.85	55.56
41	0.6546	0.7584	0.85	54.91
42	0.6540	0.7483	0.84	55.44
43	0.6544	0.7573	0.84	56.08
44	0.6532	0.7718	0.86	56.18
45	0.6523	0.7728	0.85	55.20
46	0.6515	0.8148	0.91	54.99
47	0.6539	0.7658	0.85	55.92
48	0.6525	0.7754	0.86	55.81
49	0.6526	0.7902	0.87	55.49
50	0.6524	0.7651	0.84	56.11
51	0.6521	0.7590	0.84	56.31
52	0.6522	0.7661	0.85	55.76
53	0.6514	0.7507	0.84	55.61
54	0.6504	0.7673	0.85	54.44
55	0.6530	0.7577	0.84	56.51
56	0.6516	0.7582	0.84	55.74
57	0.6507	0.7561	0.83	56.11
58	0.6515	0.7555	0.84	55.86
59	0.6523	0.7535	0.83	55.35
60	0.6503	0.7660	0.85	55.81
61	0.6515	0.7524	0.84	55.75
62	0.6508	0.7571	0.85	55.39
63	0.6504	0.7634	0.85	56.37
64	0.6494	0.7565	0.84	56.12
65	0.6511	0.7612	0.85	56.33
66	0.6503	0.7682	0.85	55.81
67	0.6500	0.7583	0.84	55.79
68	0.6508	0.7542	0.84	56.21
69	0.6491	0.7566	0.84	55.76
70	0.6507	0.7498	0.83	55.96
71	0.6515	0.7765	0.86	55.57
72	0.6493	0.7730	0.86	56.04
73	0.6482	0.7462	0.83	55.86
74	0.6487	0.7523	0.83	56.30
75	0.6487	0.7772	0.87	55.76
76	0.6502	0.7680	0.86	55.82
77	0.6486	0.7510	0.84	56.24
78	0.6496	0.7689	0.86	56.06
79	0.6486	0.7791	0.86	55.85
80	0.6517	0.7598	0.85	55.44
81	0.6486	0.7997	0.87	55.48
82	0.6498	0.7696	0.85	55.86
83	0.6484	0.7527	0.84	55.38
84	0.6495	0.7716	0.86	56.12
85	0.6489	0.7611	0.85	56.07
86	0.6490	0.7543	0.84	56.27
87	0.6482	0.7563	0.84	55.19
88	0.6495	0.7585	0.84	56.26
89	0.6483	0.7685	0.85	56.05
90	0.6482	0.7517	0.84	55.21
91	0.6480	0.7592	0.85	56.05
92	0.6486	0.7828	0.88	55.50
93	0.6488	0.7651	0.85	56.09
94	0.6489	0.7812	0.87	56.12
95	0.6472	0.7506	0.84	55.80
96	0.6474	0.7601	0.83	55.44
97	0.6471	0.7578	0.84	56.08
98	0.6481	0.7744	0.86	55.93
99	0.6480	0.7601	0.84	55.72
100	0.6487	0.7543	0.84	55.79
101	0.6472	0.7535	0.84	55.53
102	0.6477	0.7618	0.85	55.70
103	0.6475	0.7518	0.85	55.52
104	0.6474	0.7578	0.84	55.69
105	0.6473	0.7458	0.84	55.15
106	0.6466	0.7572	0.84	55.48
107	0.6488	0.8060	0.90	55.03
108	0.6469	0.7622	0.84	55.80
109	0.6462	0.7560	0.85	55.78
110	0.6476	0.7647	0.85	55.69
111	0.6468	0.7793	0.86	55.84
112	0.6475	0.7514	0.83	55.82
113	0.6459	0.7583	0.84	55.71
114	0.6469	0.7695	0.86	55.58
115	0.6475	0.7633	0.84	55.95
116	0.6464	0.7666	0.85	56.07
117	0.6460	0.7579	0.85	56.06
118	0.6477	0.7574	0.84	56.42
119	0.6467	0.7719	0.85	55.93
120	0.6467	0.7499	0.83	55.64
121	0.6476	0.7593	0.84	55.81
122	0.6469	0.7587	0.84	56.00
123	0.6469	0.7585	0.84	55.95
124	0.6473	0.7489	0.83	55.54
125	0.6454	0.7516	0.85	55.60
126	0.6461	0.7519	0.84	55.42
127	0.6453	0.7747	0.86	55.96
128	0.6458	0.7577	0.85	55.08
129	0.6460	0.7568	0.85	55.65
130	0.6472	0.7649	0.85	55.80
131	0.6443	0.7597	0.84	55.83
132	0.6470	0.7534	0.84	55.60
133	0.6456	0.7740	0.86	55.74
134	0.6452	0.7794	0.87	55.01
135	0.6462	0.7480	0.84	55.70
136	0.6450	0.7541	0.84	55.82
137	0.6447	0.7597	0.85	55.60
138	0.6463	0.7443	0.82	56.24
139	0.6473	0.7799	0.86	56.23
140	0.6449	0.7548	0.84	56.19
141	0.6460	0.7559	0.83	55.54
142	0.6449	0.7689	0.85	55.82
143	0.6443	0.7602	0.84	56.00
144	0.6459	0.7635	0.85	56.25
145	0.6453	0.7692	0.86	55.78
146	0.6447	0.7597	0.84	56.06
147	0.6448	0.7624	0.85	55.42
148	0.6451	0.7559	0.85	55.09
149	0.6444	0.7808	0.87	55.45
150	0.6458	0.7472	0.84	55.45
151	0.6442	0.7865	0.87	55.73
152	0.6466	0.7524	0.84	55.54
153	0.6440	0.7840	0.86	56.23
154	0.6458	0.7607	0.85	55.51
155	0.6452	0.7571	0.84	56.23
156	0.6446	0.7951	0.88	55.55
157	0.6456	0.7546	0.84	55.85
158	0.6458	0.7643	0.85	56.05
159	0.6454	0.7690	0.85	55.84
160	0.6454	0.7735	0.86	55.92
161	0.6455	0.7592	0.85	56.36
162	0.6446	0.7715	0.86	55.86
163	0.6454	0.7540	0.84	55.57
164	0.6447	0.7643	0.85	55.62
165	0.6450	0.7546	0.84	55.89
166	0.6449	0.7705	0.85	55.31
167	0.6453	0.7591	0.84	56.02
168	0.6448	0.7567	0.84	55.84
169	0.6426	0.7756	0.87	55.41
170	0.6442	0.7602	0.85	55.95
171	0.6437	0.7650	0.84	56.57
172	0.6448	0.7587	0.83	55.82
173	0.6461	0.7678	0.85	55.83
174	0.6449	0.7682	0.85	55.92
175	0.6446	0.7506	0.83	55.99
176	0.6451	0.7713	0.86	55.93
177	0.6453	0.7582	0.85	55.47
178	0.6442	0.7744	0.86	56.41
179	0.6445	0.7586	0.83	55.92
180	0.6434	0.7567	0.84	55.97
181	0.6436	0.7581	0.84	55.86
182	0.6448	0.7689	0.86	55.86
183	0.6427	0.7577	0.84	55.37
184	0.6440	0.7586	0.84	55.82
185	0.6444	0.7753	0.87	55.25
186	0.6438	0.7632	0.85	55.94
187	0.6446	0.7634	0.85	55.85
188	0.6433	0.7494	0.84	55.78
189	0.6450	0.7693	0.86	55.64
190	0.6446	0.7879	0.88	55.65
191	0.6453	0.7776	0.87	55.72
192	0.6449	0.7723	0.86	55.85
193	0.6448	0.7561	0.84	56.34
194	0.6438	0.7552	0.84	55.71
195	0.6438	0.7582	0.85	55.84
196	0.6455	0.7727	0.86	55.56
197	0.6442	0.7689	0.85	55.51
198	0.6440	0.7689	0.86	55.52
199	0.6443	0.7618	0.85	55.51
200	0.6445	0.7768	0.87	55.73

