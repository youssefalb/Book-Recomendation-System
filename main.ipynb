{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a78c8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47595919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "dtypes = {'ISBN': 'str', 'Book-Title': 'str', 'Book-Author': 'str', 'Year-Of-Publication': 'str', 'Publisher': 'str', 'Image-URL-S': 'str', 'Image-URL-M': 'str', 'Image-URL-L': 'str'}\n",
    "\n",
    "# books_df = pd.read_csv('dataset/Books.csv', dtype=dtypes)\n",
    "# users_df = pd.read_csv('dataset/Users.csv')\n",
    "ratings_df = pd.read_csv('dataset/Ratings.csv')\n",
    "# movie_ratings_df = pd.read_csv('dataset/MovieRatings.csv')\n",
    "ratings_df['Book-Rating'] = ratings_df['Book-Rating'] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4722902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ratings_df.merge(books_df, how=\"left\", on=\"ISBN\")\n",
    "# df.head().to_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a2953c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   User-ID      1149780 non-null  int64  \n",
      " 1   ISBN         1149780 non-null  object \n",
      " 2   Book-Rating  1149780 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          User-ID         ISBN  Book-Rating\n",
       "0         276725   034545104X          0.0\n",
       "1         276726   0155061224          2.5\n",
       "2         276727   0446520802          0.0\n",
       "3         276729   052165615X          1.5\n",
       "4         276729   0521795028          3.0\n",
       "...          ...          ...          ...\n",
       "1149775   276704   1563526298          4.5\n",
       "1149776   276706   0679447156          0.0\n",
       "1149777   276709   0515107662          5.0\n",
       "1149778   276721   0590442449          5.0\n",
       "1149779   276723  05162443314          4.0\n",
       "\n",
       "[1149780 rows x 3 columns]>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.info()\n",
    "ratings_df.head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd7fc2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          User-ID         ISBN  Book-Rating\n",
       "1         276726   0155061224          2.5\n",
       "3         276729   052165615X          1.5\n",
       "4         276729   0521795028          3.0\n",
       "6         276736   3257224281          4.0\n",
       "7         276737   0600570967          3.0\n",
       "...          ...          ...          ...\n",
       "1149773   276704   0806917695          2.5\n",
       "1149775   276704   1563526298          4.5\n",
       "1149777   276709   0515107662          5.0\n",
       "1149778   276721   0590442449          5.0\n",
       "1149779   276723  05162443314          4.0\n",
       "\n",
       "[433671 rows x 3 columns]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean mask that is True for rows that don't have a Book-Rating of 0\n",
    "mask = ratings_df['Book-Rating'] != 0\n",
    "\n",
    "# Use boolean indexing to select only the rows that don't have a Book-Rating of 0\n",
    "ratings_df = ratings_df[mask]\n",
    "ratings_df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66eadb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youssef albali\\AppData\\Local\\Temp\\ipykernel_8436\\1473222708.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings_df['User-ID'] = lbl_user.fit_transform(ratings_df['User-ID'].values)\n",
      "C:\\Users\\youssef albali\\AppData\\Local\\Temp\\ipykernel_8436\\1473222708.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings_df['ISBN'] = lbl_book.fit_transform(ratings_df['ISBN'].values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          User-ID    ISBN  Book-Rating\n",
       "133        77209    2884          5.0\n",
       "134        77209   15804          4.5\n",
       "135        77209   16137          5.0\n",
       "136        77209   17027          4.5\n",
       "137        77209   39925          4.5\n",
       "...          ...     ...          ...\n",
       "1149743    77175  117346          5.0\n",
       "1149744    77175  117457          5.0\n",
       "1149745    77175  125788          5.0\n",
       "1149746    77175  134545          3.0\n",
       "1149747    77175  141488          3.5\n",
       "\n",
       "[295561 rows x 3 columns]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_book = preprocessing.LabelEncoder()\n",
    "ratings_df['User-ID'] = lbl_user.fit_transform(ratings_df['User-ID'].values)\n",
    "ratings_df['ISBN'] = lbl_book.fit_transform(ratings_df['ISBN'].values)\n",
    "\n",
    "user_ratings_count = Counter(ratings_df['User-ID'])\n",
    "\n",
    "# Find users with less than 4 ratings\n",
    "users_to_remove = [user_id for user_id, count in user_ratings_count.items() if count < 10]\n",
    "\n",
    "# Remove users with less than 4 ratings from the dataset\n",
    "ratings_df = ratings_df[~ratings_df['User-ID'].isin(users_to_remove)]\n",
    "ratings_df.head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1d73294",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(\n",
    "    ratings_df, test_size=0.1, stratify=ratings_df['Book-Rating'].values\n",
    ")\n",
    "\n",
    "# train_df.to_csv('dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d26b448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29557, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eebd6d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266004\n",
      "266004\n",
      "266004\n",
      "266004\n"
     ]
    }
   ],
   "source": [
    "from bookDataset import BookDataset\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = BookDataset(train_df['User-ID'].values, train_df['ISBN'].values, train_df['Book-Rating'].values)\n",
    "valid_dataset = BookDataset(valid_df['User-ID'].values, valid_df['ISBN'].values, valid_df['Book-Rating'].values)\n",
    "\n",
    "# Create train and validation data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0ff1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecommender(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_isbns, embedding_dim):\n",
    "        super(BookRecommender, self).__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_dim)\n",
    "        self.isbn_embedding = torch.nn.Embedding(num_embeddings=num_isbns, embedding_dim=embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim * 2, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, users, isbns):\n",
    "        user_embeds = self.user_embedding(users.long())\n",
    "        isbn_embeds = self.isbn_embedding(isbns.long())\n",
    "        embeds = torch.cat([user_embeds, isbn_embeds], dim=1)\n",
    "        x = torch.relu(self.fc1(embeds.view(embeds.size(0), -1)))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "622eca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BookRecommender(\n",
      "  (user_embedding): Embedding(77805, 64)\n",
      "  (isbn_embedding): Embedding(185973, 64)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BookRecommender(num_users=len(lbl_user.classes_),\n",
    "                        num_isbns=len(lbl_book.classes_),\n",
    "                        embedding_dim=64)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca5cdff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.7)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b7f1e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the DataLoader: 4156\n",
      "Learning Rate: [0.1]\n",
      "Epoch [1/2], Loss: 0.7994\n",
      "Learning Rate: [0.1]\n",
      "Epoch [2/2], Loss: 0.7299\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from bookDataset import BookDataset\n",
    "num_batches = len(train_loader)\n",
    "\n",
    "print(\"Number of batches in the DataLoader:\", num_batches)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch[\"user_id\"], batch[\"isbn\"])\n",
    "        loss = criterion(outputs, batch[\"rating\"].unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * batch_size\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(\"Learning Rate:\", scheduler.get_last_lr())\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))\n",
    "    scheduler.step()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b39ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 64\n",
      "Validation RMSE: 0.81\n",
      "Validation Accuracy: 60.31%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "print('hello', batch_size)\n",
    "predictions = []\n",
    "targets = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        user_ids, isbns, ratings = batch['user_id'], batch['isbn'], batch['rating']\n",
    "        outputs = model(user_ids, isbns)\n",
    "        ratings = ratings.view(-1, 1)  # Reshape the target tensor\n",
    "        predicted_ratings = torch.round(outputs)  # Round the predicted ratings\n",
    "#         print(ratings.shape)\n",
    "        predictions.extend(predicted_ratings.tolist())\n",
    "        targets.extend(ratings.tolist())\n",
    "    \n",
    "        correct = ((predicted_ratings == ratings) | (predicted_ratings == ratings - 0.5) | (predicted_ratings == ratings + 0.5)).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += ratings.size(0)\n",
    "\n",
    "# Calculate mean squared error\n",
    "rmse = mean_squared_error(targets, predictions)\n",
    "print('Validation RMSE: {:.2f}'.format(rmse))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print('Validation Accuracy: {:.2f}%'.format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aea322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2198ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404ea82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
