{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a78c8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "47595919",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'ISBN': 'str', 'Book-Title': 'str', 'Book-Author': 'str', 'Year-Of-Publication': 'str', 'Publisher': 'str', 'Image-URL-S': 'str', 'Image-URL-M': 'str', 'Image-URL-L': 'str'}\n",
    "\n",
    "# books_df = pd.read_csv('dataset/Books.csv', dtype=dtypes)\n",
    "# users_df = pd.read_csv('dataset/Users.csv')\n",
    "# ratings_df = pd.read_csv('dataset/Ratings.csv')\n",
    "movie_ratings_df = pd.read_csv('dataset/MovieRatings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c4722902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ratings_df.merge(books_df, how=\"left\", on=\"ISBN\")\n",
    "# df.head().to_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4a2953c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "# ratings_df.info()\n",
    "# ratings_df.head\n",
    "movie_ratings_df.head()\n",
    "movie_ratings_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bd7fc2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          User-ID    ISBN  Book-Rating\n",
       "16         77186    4251            9\n",
       "19         77186   84416            9\n",
       "20         77186   90160            8\n",
       "21         77186  129959            7\n",
       "23         77186  149425            7\n",
       "...          ...     ...          ...\n",
       "1149761    77176   30893            6\n",
       "1149762    77176   42010            5\n",
       "1149771    77176   97560            7\n",
       "1149773    77176  111085            5\n",
       "1149775    77176  137773            9\n",
       "\n",
       "[353117 rows x 3 columns]>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean mask that is True for rows that don't have a Book-Rating of 0\n",
    "mask = ratings_df['Book-Rating'] != 0\n",
    "\n",
    "# Use boolean indexing to select only the rows that don't have a Book-Rating of 0\n",
    "ratings_df = ratings_df[mask]\n",
    "ratings_df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66eadb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         userId  movieId  rating   timestamp\n",
       "0            0        0     4.0   964982703\n",
       "1            0        2     4.0   964981247\n",
       "2            0        5     4.0   964982224\n",
       "3            0       43     5.0   964983815\n",
       "4            0       46     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     609     9416     4.0  1493848402\n",
       "100832     609     9443     5.0  1493850091\n",
       "100833     609     9444     5.0  1494273047\n",
       "100834     609     9445     5.0  1493846352\n",
       "100835     609     9485     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# lbl_user = preprocessing.LabelEncoder()\n",
    "# lbl_book = preprocessing.LabelEncoder()\n",
    "# ratings_df['User-ID'] = lbl_user.fit_transform(ratings_df['User-ID'].values)\n",
    "# ratings_df['ISBN'] = lbl_book.fit_transform(ratings_df['ISBN'].values)\n",
    "\n",
    "# user_ratings_count = Counter(ratings_df['User-ID'])\n",
    "\n",
    "# # Find users with less than 4 ratings\n",
    "# users_to_remove = [user_id for user_id, count in user_ratings_count.items() if count < 4]\n",
    "\n",
    "# # Remove users with less than 4 ratings from the dataset\n",
    "# ratings_df = ratings_df[~ratings_df['User-ID'].isin(users_to_remove)]\n",
    "# ratings_df.head\n",
    "\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "movie_ratings_df.userId = lbl_user.fit_transform(movie_ratings_df.userId.values)\n",
    "movie_ratings_df.movieId = lbl_movie.fit_transform(movie_ratings_df.movieId.values)\n",
    "movie_ratings_df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d1d73294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, valid_df = train_test_split(\n",
    "#     ratings_df, test_size=0.1, stratify=ratings_df['Book-Rating'].values\n",
    "# )\n",
    "# train_df.to_csv('dataset/test.csv')\n",
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    movie_ratings_df, test_size=0.1, stratify=movie_ratings_df.rating.values\n",
    ")\n",
    "train_df.to_csv('dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5d26b448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10084, 4)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eebd6d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90752\n",
      "90752\n",
      "90752\n",
      "90752\n"
     ]
    }
   ],
   "source": [
    "from bookDataset import BookDataset\n",
    "\n",
    "# Create train and validation datasets\n",
    "# train_dataset = BookDataset(train_df['User-ID'].values, train_df['ISBN'].values, train_df['Book-Rating'].values)\n",
    "# valid_dataset = BookDataset(valid_df['User-ID'].values, valid_df['ISBN'].values, valid_df['Book-Rating'].values)\n",
    "\n",
    "train_dataset = BookDataset(train_df.userId.values, train_df.movieId.values, train_df.rating.values)\n",
    "valid_dataset = BookDataset(valid_df.userId.values, valid_df.movieId.values, valid_df.rating.values)\n",
    "# print(ratings_df.head())\n",
    "print(len(train_dataset))\n",
    "print(len(train_dataset.user_ids))\n",
    "print(len(train_dataset.isbns))\n",
    "print(len(train_dataset.ratings))\n",
    "# Create train and validation data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d0ff1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecommender(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_isbns, embedding_dim):\n",
    "        super(BookRecommender, self).__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_dim)\n",
    "        self.isbn_embedding = torch.nn.Embedding(num_embeddings=num_isbns, embedding_dim=embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim * 2, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, users, isbns):\n",
    "        user_embeds = self.user_embedding(users.long())\n",
    "        isbn_embeds = self.isbn_embedding(isbns.long())\n",
    "        embeds = torch.cat([user_embeds, isbn_embeds], dim=1)\n",
    "        x = torch.relu(self.fc1(embeds.view(embeds.size(0), -1)))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "622eca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BookRecommender(\n",
      "  (user_embedding): Embedding(610, 64)\n",
      "  (isbn_embedding): Embedding(9724, 64)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model = BookRecommender(num_users=len(lbl_user.classes_),\n",
    "#                         num_isbns=len(lbl_book.classes_),\n",
    "#                         embedding_dim=64)\n",
    "\n",
    "model = BookRecommender(num_users=len(lbl_user.classes_),\n",
    "                        num_isbns=len(lbl_movie.classes_),\n",
    "                        embedding_dim=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ca5cdff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3b7f1e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the DataLoader: 1418\n",
      "Epoch [1/5], Loss: 0.9833\n",
      "Epoch [2/5], Loss: 0.8958\n",
      "Epoch [3/5], Loss: 0.8635\n",
      "Epoch [4/5], Loss: 0.8436\n",
      "Epoch [5/5], Loss: 0.8269\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from bookDataset import BookDataset\n",
    "num_batches = len(train_loader)\n",
    "\n",
    "print(\"Number of batches in the DataLoader:\", num_batches)\n",
    "\n",
    "i=0        \n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "#         i += 1\n",
    "#             print(\"Id from training loop: \", i)\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(batch[\"user_id\"], batch[\"isbn\"])\n",
    "        loss = criterion(outputs, batch[\"rating\"].unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * batch_size\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1b39ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 64\n",
      "Validation RMSE: 0.98\n",
      "Validation Accuracy: 29.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "print('hello', batch_size)\n",
    "predictions = []\n",
    "targets = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        user_ids, isbns, ratings = batch['user_id'], batch['isbn'], batch['rating']\n",
    "        outputs = model(user_ids, isbns)\n",
    "        ratings = ratings.view(-1, 1)  # Reshape the target tensor\n",
    "        predicted_ratings = torch.round(outputs)  # Round the predicted ratings\n",
    "\n",
    "        predictions.extend(predicted_ratings.tolist())\n",
    "        targets.extend(ratings.tolist())\n",
    "    \n",
    "        correct = (predicted_ratings == ratings).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += ratings.size(0)\n",
    "\n",
    "# Calculate mean squared error\n",
    "rmse = mean_squared_error(targets, predictions, squared=False)\n",
    "print('Validation RMSE: {:.2f}'.format(rmse))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print('Validation Accuracy: {:.2f}%'.format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aea322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2198ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
