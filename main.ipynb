{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78c8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47595919",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'ISBN': 'str', 'Book-Title': 'str', 'Book-Author': 'str', 'Year-Of-Publication': 'str', 'Publisher': 'str', 'Image-URL-S': 'str', 'Image-URL-M': 'str', 'Image-URL-L': 'str'}\n",
    "\n",
    "books_df = pd.read_csv('dataset/Books.csv', dtype=dtypes)\n",
    "users_df = pd.read_csv('dataset/Users.csv')\n",
    "ratings_df = pd.read_csv('dataset/Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4722902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ratings_df.merge(books_df, how=\"left\", on=\"ISBN\")\n",
    "df.head().to_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2953c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          User-ID         ISBN  Book-Rating\n",
       "0         276725   034545104X            0\n",
       "1         276726   0155061224            5\n",
       "2         276727   0446520802            0\n",
       "3         276729   052165615X            3\n",
       "4         276729   0521795028            6\n",
       "...          ...          ...          ...\n",
       "1149775   276704   1563526298            9\n",
       "1149776   276706   0679447156            0\n",
       "1149777   276709   0515107662           10\n",
       "1149778   276721   0590442449           10\n",
       "1149779   276723  05162443314            8\n",
       "\n",
       "[1149780 rows x 3 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.info()\n",
    "ratings_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7fc2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          User-ID         ISBN  Book-Rating\n",
       "1         276726   0155061224            5\n",
       "3         276729   052165615X            3\n",
       "4         276729   0521795028            6\n",
       "6         276736   3257224281            8\n",
       "7         276737   0600570967            6\n",
       "...          ...          ...          ...\n",
       "1149773   276704   0806917695            5\n",
       "1149775   276704   1563526298            9\n",
       "1149777   276709   0515107662           10\n",
       "1149778   276721   0590442449           10\n",
       "1149779   276723  05162443314            8\n",
       "\n",
       "[433671 rows x 3 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean mask that is True for rows that don't have a Book-Rating of 0\n",
    "mask = ratings_df['Book-Rating'] != 0\n",
    "\n",
    "# Use boolean indexing to select only the rows that don't have a Book-Rating of 0\n",
    "ratings_df = ratings_df[mask]\n",
    "ratings_df.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eadb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_book = preprocessing.LabelEncoder()\n",
    "ratings_df['User-ID'] = lbl_user.fit_transform(ratings_df['User-ID'].values)\n",
    "ratings_df['ISBN'] = lbl_book.fit_transform(ratings_df['ISBN'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d73294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43368, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    ratings_df, test_size=0.1\n",
    ")\n",
    "train_df.to_csv('dataset/test.csv')\n",
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d26b448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43368, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eebd6d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390303\n",
      "390303\n",
      "390303\n",
      "390303\n"
     ]
    }
   ],
   "source": [
    "from bookDataset import BookDataset\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = BookDataset(train_df['User-ID'].values, train_df['ISBN'].values, train_df['Book-Rating'].values)\n",
    "valid_dataset = BookDataset(valid_df['User-ID'].values, valid_df['ISBN'].values, valid_df['Book-Rating'].values)\n",
    "# print(ratings_df.head())\n",
    "print(len(train_dataset))\n",
    "print(len(train_dataset.user_ids))\n",
    "print(len(train_dataset.isbns))\n",
    "print(len(train_dataset.ratings))\n",
    "# Create train and validation data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ff1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecommender(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_isbns, embedding_dim):\n",
    "        super(BookRecommender, self).__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_dim)\n",
    "        self.isbn_embedding = torch.nn.Embedding(num_embeddings=num_isbns, embedding_dim=embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim * 2, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, users, isbns):\n",
    "        user_embeds = self.user_embedding(users.long())\n",
    "        isbn_embeds = self.isbn_embedding(isbns.long())\n",
    "        embeds = torch.cat([user_embeds, isbn_embeds], dim=1)\n",
    "        x = torch.relu(self.fc1(embeds.view(embeds.size(0), -1)))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "622eca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BookRecommender(\n",
      "  (user_embedding): Embedding(77805, 64)\n",
      "  (isbn_embedding): Embedding(185973, 64)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BookRecommender(num_users=len(lbl_user.classes_),\n",
    "                        num_isbns=len(lbl_book.classes_),\n",
    "                        embedding_dim=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca5cdff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "embedding_dim = 32\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b7f1e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the DataLoader: 12196\n",
      "Epoch [1/10], Loss: 6.7902\n",
      "Epoch [2/10], Loss: 6.5811\n",
      "Epoch [3/10], Loss: 6.4606\n",
      "Epoch [4/10], Loss: 6.3899\n",
      "Epoch [5/10], Loss: 6.3290\n",
      "Epoch [6/10], Loss: 6.2786\n",
      "Epoch [7/10], Loss: 6.2413\n",
      "Epoch [8/10], Loss: 6.2001\n",
      "Epoch [9/10], Loss: 6.1645\n",
      "Epoch [10/10], Loss: 6.1262\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from bookDataset import BookDataset\n",
    "num_batches = len(train_loader)\n",
    "\n",
    "print(\"Number of batches in the DataLoader:\", num_batches)\n",
    "\n",
    "i=0        \n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "#         i += 1\n",
    "#             print(\"Id from training loop: \", i)\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(batch[\"user_id\"], batch[\"isbn\"])\n",
    "        loss = criterion(outputs, batch[\"rating\"].unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * batch_size\n",
    "#         print(i)\n",
    "        i += 1\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39ce8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aea322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2198ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
