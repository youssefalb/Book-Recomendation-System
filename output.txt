Scenario 1: Learning Rate = 0.1, Loss Function = MSELoss
Number of Batches: 64
Epoch	Loss	Validation RMSE	Validation Accuracy
1	0.7971	0.7495	0.91	0.59
2	0.7290	0.7168	0.89	0.61
3	0.7031	0.6991	0.88	0.62
4	0.6862	0.6942	0.88	0.61
5	0.6756	0.6970	0.88	0.62
6	0.6678	0.6837	0.88	0.62
7	0.6615	0.6835	0.87	0.62
8	0.6560	0.6787	0.88	0.63
9	0.6509	0.6759	0.87	0.62
10	0.6473	0.6801	0.88	0.63

Scenario 2: Learning Rate = 0.1, Loss Function = MSELoss
Number of Batches: 64
Epoch	Loss	Validation RMSE	Validation Accuracy
1	0.8005	0.7480	0.90	0.59
2	0.7313	0.7206	0.90	0.61
3	0.7035	0.7015	0.88	0.62
4	0.6871	0.6946	0.88	0.62
5	0.6766	0.6884	0.88	0.61
6	0.6680	0.6852	0.88	0.62
7	0.6608	0.6754	0.87	0.63
8	0.6558	0.6890	0.88	0.64
9	0.6505	0.6780	0.87	0.62
10	0.6468	0.6761	0.87	0.62
11	0.6434	0.6782	0.88	0.62
12	0.6408	0.6765	0.88	0.62
13	0.6375	0.6746	0.87	0.64
14	0.6344	0.6729	0.87	0.63
15	0.6319	0.6734	0.87	0.64
16	0.6299	0.6725	0.87	0.63
17	0.6273	0.6830	0.88	0.64
18	0.6253	0.6793	0.88	0.61
19	0.6233	0.6625	0.87	0.63
20	0.6209	0.6689	0.87	0.63
21	0.6197	0.6801	0.88	0.63
22	0.6176	0.6659	0.87	0.63
23	0.6159	0.6690	0.87	0.63
24	0.6146	0.6759	0.87	0.63
25	0.6124	0.6760	0.88	0.62
26	0.6113	0.6722	0.87	0.63
27	0.6094	0.6704	0.87	0.63
28	0.6082	0.6687	0.87	0.63
29	0.6068	0.6706	0.87	0.62
30	0.6054	0.6784	0.88	0.61
31	0.6035	0.6708	0.87	0.62
32	0.6024	0.6761	0.88	0.62
33	0.6014	0.6819	0.88	0.61
34	0.6001	0.6744	0.87	0.62
35	0.5987	0.6781	0.87	0.63
36	0.5971	0.6775	0.88	0.62
37	0.5958	0.6761	0.87	0.62
38	0.5947	0.6823	0.88	0.61
39	0.5935	0.6759	0.87	0.64
40	0.5922	0.6778	0.87	0.63
41	0.5911	0.6828	0.88	0.62
42	0.5892	0.6737	0.87	0.63
43	0.5893	0.6709	0.87	0.63
44	0.5874	0.6737	0.87	0.63
45	0.5857	0.6843	0.88	0.63
46	0.5852	0.7276	0.90	0.63
47	0.5837	0.6771	0.88	0.62
48	0.5823	0.6737	0.87	0.63
49	0.5811	0.6823	0.88	0.63
50	0.5801	0.6873	0.88	0.63
51	0.5790	0.6907	0.89	0.62
52	0.5774	0.6856	0.88	0.62
53	0.5768	0.6842	0.88	0.63
54	0.5753	0.6846	0.88	0.63
55	0.5745	0.6769	0.87	0.62
56	0.5730	0.6865	0.88	0.62
57	0.5721	0.6843	0.88	0.62
58	0.5709	0.6869	0.88	0.63
59	0.5694	0.6897	0.88	0.63
60	0.5687	0.6940	0.89	0.61
61	0.5678	0.6915	0.88	0.62
62	0.5665	0.6993	0.89	0.63
63	0.5651	0.7109	0.89	0.63
64	0.5639	0.7011	0.89	0.62
65	0.5632	0.7045	0.89	0.60
66	0.5616	0.6997	0.89	0.63
67	0.5606	0.6996	0.89	0.63
68	0.5601	0.6938	0.89	0.62
69	0.5583	0.7006	0.89	0.61
70	0.5575	0.7039	0.89	0.63
71	0.5564	0.6903	0.88	0.62
72	0.5551	0.7100	0.89	0.63
73	0.5543	0.7139	0.90	0.61
74	0.5530	0.6984	0.89	0.62
75	0.5516	0.7042	0.89	0.62
76	0.5511	0.7057	0.89	0.63
77	0.5493	0.7069	0.89	0.61
78	0.5479	0.7109	0.90	0.62
79	0.5474	0.6995	0.89	0.62
80	0.5464	0.7069	0.89	0.61
81	0.5445	0.7370	0.91	0.63
82	0.5437	0.7034	0.89	0.62
83	0.5427	0.7107	0.89	0.62
84	0.5414	0.7019	0.89	0.62
85	0.5397	0.7383	0.91	0.62
86	0.5387	0.7138	0.90	0.60
87	0.5379	0.7132	0.90	0.62
88	0.5370	0.7254	0.90	0.62
89	0.5356	0.7207	0.90	0.62
90	0.5344	0.7221	0.90	0.61
91	0.5332	0.7167	0.90	0.61
92	0.5326	0.7166	0.90	0.62
93	0.5306	0.7207	0.90	0.61
94	0.5296	0.7202	0.90	0.61
95	0.5286	0.7135	0.90	0.61
96	0.5270	0.7165	0.90	0.61
97	0.5260	0.7171	0.90	0.61
98	0.5248	0.7299	0.91	0.60
99	0.5236	0.7244	0.90	0.61
100	0.5223	0.7197	0.90	0.61

Scenario 3: Learning Rate = 0.01, Loss Function = SmoothL1Loss
Number of Batches: 128
Scheduler: StepLR
Epoch	Loss	Validation RMSE	Validation Accuracy
1	0.4477	0.3677	0.93	0.57
2	0.3628	0.3599	0.92	0.58
3	0.3556	0.3540	0.92	0.58
4	0.3508	0.3504	0.92	0.58
5	0.3470	0.3471	0.91	0.59
6	0.3437	0.3446	0.91	0.59
7	0.3407	0.3423	0.91	0.59
8	0.3380	0.3402	0.91	0.60
9	0.3356	0.3380	0.91	0.59
10	0.3333	0.3362	0.91	0.60
11	0.3312	0.3344	0.91	0.60
12	0.3293	0.3328	0.91	0.60
13	0.3275	0.3317	0.91	0.60
14	0.3257	0.3306	0.91	0.60
15	0.3241	0.3294	0.91	0.60
16	0.3224	0.3281	0.91	0.61
17	0.3209	0.3272	0.90	0.60
18	0.3194	0.3259	0.90	0.60
19	0.3180	0.3245	0.90	0.61
20	0.3168	0.3235	0.90	0.61

Scenario 4: Learning Rate = 0.01, Loss Function = SmoothL1Loss
Number of Batches: 128
Scheduler: StepLR
Epoch	Loss	Validation RMSE	Validation Accuracy
1	0.4674	0.3667	0.93	0.57
2	0.3616	0.3589	0.92	0.58
3	0.3551	0.3539	0.92	0.58
4	0.3506	0.3505	0.92	0.58
5	0.3468	0.3477	0.92	0.59
6	0.3432	0.3441	0.91	0.59
7	0.3398	0.3416	0.91	0.59
8	0.3366	0.3388	0.91	0.59
9	0.3338	0.3366	0.91	0.60
10	0.3311	0.3342	0.91	0.60
11	0.3287	0.3326	0.91	0.60
12	0.3266	0.3322	0.91	0.59
13	0.3246	0.3297	0.90	0.60
14	0.3228	0.3276	0.90	0.60
15	0.3212	0.3267	0.90	0.60
16	0.3196	0.3256	0.90	0.60
17	0.3182	0.3249	0.90	0.60
18	0.3168	0.3239	0.90	0.61
19	0.3155	0.3225	0.90	0.61
20	0.3143	0.3217	0.90	0.61
21	0.3131	0.3208	0.90	0.61
22	0.3118	0.3200	0.90	0.61
23	0.3107	0.3193	0.90	0.61
24	0.3094	0.3182	0.90	0.61
25	0.3084	0.3173	0.89	0.61
26	0.3072	0.3164	0.90	0.61
27	0.3061	0.3157	0.89	0.61
28	0.3050	0.3151	0.89	0.61
29	0.3040	0.3146	0.89	0.62
30	0.3029	0.3130	0.89	0.62
31	0.3019	0.3123	0.89	0.62
32	0.3009	0.3111	0.89	0.62
33	0.2999	0.3112	0.89	0.62
34	0.2990	0.3096	0.89	0.62
35	0.2982	0.3089	0.88	0.62
36	0.2972	0.3089	0.88	0.62
37	0.2963	0.3078	0.89	0.62
38	0.2955	0.3070	0.89	0.63
39	0.2947	0.3064	0.88	0.62
40	0.2940	0.3056	0.88	0.62
41	0.2933	0.3045	0.88	0.62
42	0.2926	0.3045	0.88	0.63
43	0.2918	0.3046	0.88	0.63
44	0.2912	0.3037	0.88	0.62
45	0.2905	0.3035	0.88	0.63
46	0.2899	0.3031	0.88	0.63
47	0.2893	0.3020	0.88	0.63
48	0.2886	0.3017	0.88	0.63
49	0.2881	0.3010	0.88	0.63
50	0.2875	0.3015	0.88	0.63
51	0.2869	0.3013	0.88	0.63
52	0.2863	0.3006	0.88	0.63
53	0.2859	0.3000	0.88	0.63
54	0.2853	0.3000	0.88	0.63
55	0.2847	0.2997	0.88	0.63
56	0.2842	0.2994	0.88	0.63
57	0.2837	0.2990	0.88	0.63
58	0.2834	0.2982	0.88	0.63
59	0.2828	0.2982	0.88	0.63
60	0.2823	0.2978	0.88	0.63
61	0.2819	0.2978	0.88	0.63
62	0.2814	0.2973	0.88	0.63
63	0.2810	0.2967	0.88	0.63
64	0.2807	0.2972	0.88	0.64
65	0.2802	0.2965	0.88	0.64
66	0.2799	0.2963	0.88	0.64
67	0.2796	0.2965	0.88	0.63
68	0.2792	0.2955	0.88	0.63
69	0.2788	0.2960	0.87	0.63
70	0.2785	0.2952	0.87	0.64
71	0.2782	0.2951	0.87	0.63
72	0.2779	0.2946	0.87	0.63
73	0.2775	0.2952	0.87	0.63
74	0.2771	0.2949	0.87	0.63
75	0.2769	0.2944	0.87	0.63
76	0.2765	0.2942	0.88	0.64
77	0.2763	0.2936	0.87	0.64
78	0.2760	0.2937	0.87	0.64
79	0.2756	0.2937	0.87	0.63
80	0.2754	0.2936	0.87	0.64
81	0.2752	0.2941	0.87	0.63
82	0.2748	0.2949	0.88	0.64
83	0.2746	0.2926	0.87	0.64
84	0.2743	0.2920	0.87	0.64
85	0.2741	0.2921	0.87	0.64
86	0.2739	0.2929	0.87	0.64
87	0.2736	0.2927	0.87	0.64
88	0.2734	0.2928	0.87	0.64
89	0.2732	0.2921	0.87	0.64
90	0.2728	0.2927	0.88	0.64
91	0.2727	0.2914	0.87	0.64
92	0.2724	0.2914	0.87	0.64
93	0.2722	0.2922	0.87	0.64
94	0.2721	0.2917	0.87	0.64
95	0.2719	0.2905	0.87	0.64
96	0.2717	0.2910	0.87	0.64
97	0.2715	0.2914	0.87	0.63
98	0.2712	0.2909	0.87	0.64
99	0.2711	0.2906	0.87	0.64
100	0.2709	0.2906	0.87	0.64
101	0.2707	0.2903	0.87	0.64
102	0.2705	0.2906	0.87	0.64
103	0.2704	0.2899	0.87	0.64
104	0.2702	0.2904	0.87	0.64
105	0.2701	0.2902	0.87	0.64
106	0.2700	0.2894	0.87	0.64
107	0.2697	0.2903	0.87	0.64
108	0.2696	0.2911	0.87	0.63
109	0.2695	0.2905	0.87	0.64
110	0.2694	0.2918	0.87	0.63
111	0.2692	0.2897	0.87	0.64
112	0.2691	0.2902	0.87	0.64
113	0.2690	0.2899	0.87	0.64
114	0.2687	0.2907	0.87	0.64
115	0.2687	0.2896	0.87	0.64
116	0.2686	0.2892	0.87	0.64
117	0.2684	0.2890	0.87	0.64
118	0.2682	0.2896	0.87	0.64
119	0.2680	0.2896	0.87	0.64
120	0.2680	0.2899	0.87	0.64
121	0.2680	0.2896	0.87	0.64
122	0.2678	0.2909	0.87	0.65
123	0.2678	0.2885	0.87	0.64
124	0.2676	0.2895	0.87	0.64
125	0.2675	0.2892	0.87	0.64
126	0.2674	0.2893	0.87	0.64
127	0.2672	0.2885	0.87	0.64
128	0.2672	0.2885	0.87	0.64
129	0.2670	0.2888	0.87	0.64
130	0.2669	0.2892	0.87	0.65
131	0.2669	0.2893	0.87	0.64
132	0.2668	0.2897	0.87	0.64
133	0.2667	0.2899	0.87	0.65
134	0.2665	0.2887	0.87	0.64
135	0.2665	0.2887	0.87	0.65
136	0.2663	0.2894	0.87	0.64
137	0.2662	0.2895	0.87	0.64
138	0.2661	0.2888	0.87	0.64
139	0.2660	0.2885	0.87	0.64
140	0.2660	0.2886	0.87	0.64
141	0.2659	0.2888	0.87	0.65
142	0.2658	0.2891	0.87	0.64
143	0.2658	0.2891	0.87	0.65
144	0.2656	0.2899	0.87	0.64
145	0.2655	0.2883	0.87	0.65
146	0.2654	0.2893	0.87	0.64
147	0.2653	0.2887	0.87	0.65
148	0.2652	0.2879	0.87	0.64
149	0.2652	0.2892	0.87	0.65
150	0.2651	0.2883	0.87	0.65
151	0.2650	0.2877	0.87	0.64
152	0.2650	0.2880	0.87	0.64
153	0.2648	0.2905	0.87	0.65
154	0.2648	0.2882	0.87	0.65
155	0.2647	0.2880	0.87	0.64
156	0.2646	0.2886	0.87	0.64
157	0.2646	0.2882	0.87	0.64
158	0.2644	0.2881	0.87	0.65
159	0.2644	0.2888	0.87	0.64
160	0.2643	0.2873	0.87	0.65
161	0.2642	0.2888	0.87	0.64
162	0.2642	0.2878	0.87	0.64
163	0.2641	0.2875	0.87	0.64
164	0.2640	0.2876	0.87	0.64
165	0.2639	0.2885	0.86	0.64
166	0.2638	0.2883	0.87	0.65
167	0.2637	0.2876	0.87	0.64
168	0.2638	0.2869	0.86	0.65
169	0.2636	0.2873	0.87	0.64
170	0.2635	0.2884	0.87	0.64
171	0.2635	0.2875	0.87	0.65
172	0.2634	0.2873	0.87	0.65
173	0.2633	0.2877	0.87	0.65
174	0.2633	0.2890	0.87	0.64
175	0.2632	0.2876	0.87	0.65
176	0.2631	0.2892	0.87	0.64
177	0.2631	0.2875	0.87	0.65
178	0.2630	0.2882	0.87	0.65
179	0.2629	0.2870	0.87	0.65
180	0.2629	0.2876	0.87	0.65
181	0.2628	0.2885	0.87	0.65
182	0.2628	0.2869	0.87	0.64
183	0.2627	0.2875	0.87	0.65
184	0.2627	0.2877	0.87	0.64
185	0.2626	0.2866	0.87	0.65
186	0.2624	0.2873	0.87	0.65
187	0.2625	0.2877	0.87	0.64
188	0.2625	0.2870	0.87	0.64
189	0.2623	0.2878	0.87	0.65
190	0.2623	0.2876	0.87	0.64
191	0.2622	0.2876	0.87	0.64
192	0.2621	0.2881	0.87	0.64
193	0.2622	0.2883	0.87	0.64
194	0.2621	0.2874	0.87	0.65
195	0.2621	0.2873	0.87	0.65
196	0.2620	0.2871	0.87	0.64
197	0.2619	0.2870	0.87	0.64
198	0.2619	0.2872	0.87	0.64
199	0.2619	0.2877	0.87	0.65
200	0.2617	0.2868	0.87	0.65

Scenario 5: Learning Rate = 0.001, Loss Function = L1Loss
Number of Batches: 32
Scheduler: ExponentialLR
Epoch	Loss	Validation RMSE	Validation Accuracy
1	0.9006	0.7384	0.95	0.56
2	0.7341	0.7272	0.93	0.57
3	0.7244	0.7206	0.93	0.58
4	0.7178	0.7155	0.92	0.58
5	0.7128	0.7117	0.92	0.58

Scenario 6: Learning Rate = 0.001, Loss Function = CrossEntropyLoss
Number of Batches: 256
Epoch	Loss	Validation RMSE	Validation Accuracy
1	0.0000	0.0000	3.95	0.00
2	0.0000	0.0000	3.95	0.00
3	0.0000	0.0000	3.95	0.00
4	0.0000	0.0000	3.95	0.00
5	0.0000	0.0000	3.95	0.00
6	0.0000	0.0000	3.95	0.00
7	0.0000	0.0000	3.95	0.00
8	0.0000	0.0000	3.95	0.00
9	0.0000	0.0000	3.95	0.00
10	0.0000	0.0000	3.95	0.00
11	0.0000	0.0000	3.95	0.00
12	0.0000	0.0000	3.95	0.00
13	0.0000	0.0000	3.95	0.00
14	0.0000	0.0000	3.95	0.00
15	0.0000	0.0000	3.95	0.00

Scenario 7: Learning Rate = 0.0001, Loss Function = BCELoss
Number of Batches: 16
Scheduler: CosineAnnealingLR
Epoch	Loss	Validation RMSE	Validation Accuracy
